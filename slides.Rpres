trump tweets
========================================================
author: web science
date: 17.01.2016
autosize: true

Mention follower (bimodal)
========================================================

![mention follower](slides-figure/trumpBig.jpg)

interaction (actor)
========================================================

![mention follower](slides-figure/bimdalBig.jpg)

ego network
========================================================

![mention follower](slides-figure/egoBig.jpg)


Trumps wordcloud
========================================================
```{r, message=FALSE, warning=FALSE, include=FALSE}
wants <- c("SocialMediaLab", "magrittr", "igraph", "ggplot2", "wordcloud", "tm", "stringr", "lubridate", "scales", "dplyr", "purrr", "tidyr", "readr", "tidytext")
has   <- wants %in% rownames(installed.packages())
if(any(!has)) install.packages(wants[!has])
lapply(wants, library, character.only=T)
```

```{r, echo=FALSE}
tweets <- read.csv("data/trumpTweets.csv")
nohandles <- str_replace_all(tweets$text, "@\\w+", "") 
wordCorpus <- Corpus(VectorSource(nohandles))
wordCorpus <- tm_map(wordCorpus,
          content_transformer(function(x) iconv(x,
              to='UTF-8',
              sub='byte')),
          mc.cores=1)
wordCorpus <- tm_map(wordCorpus,
                     removePunctuation
                     ,lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     content_transformer(tolower),
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     removeWords,
                     stopwords("english"),
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     removeNumbers,
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     stripWhitespace,
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     removeWords,
  c("trump","realdonaldtrump","the",
    "like","http","https","httpst"))
pal <- brewer.pal(9,"Reds")
pal <- pal[-(1:4)]
set.seed(123)
wordcloud(words = wordCorpus, scale=c(6,0.1),
          max.words=250,
          random.order=FALSE,
          rot.per=0.35,
          use.r.layout=FALSE,
          colors=pal)
```

#trump hashtag wordcloud
========================================================

```{r, echo=FALSE}
tweets <- read.csv("data/trumpHashtagTweets.csv")
nohandles <- str_replace_all(tweets$text, "@\\w+", "") 
wordCorpus <- Corpus(VectorSource(nohandles))
wordCorpus <- tm_map(wordCorpus,
  content_transformer(function(x) iconv(x,
         to='UTF-8',
         sub='byte')),
  mc.cores=1)
wordCorpus <- tm_map(wordCorpus,
                     removePunctuation,
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     content_transformer(tolower),
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     removeWords,
                     stopwords("english"),
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     removeNumbers,
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     stripWhitespace,
                     lazy=TRUE)
wordCorpus <- tm_map(wordCorpus,
                     removeWords,
  c("trump","realdonaldtrump","the",
    "like","http","https","httpst"))
pal <- brewer.pal(9,"Reds")
pal <- pal[-(1:4)]
set.seed(123)
wordcloud(words = wordCorpus,
          scale=c(6,0.1),
          max.words=250,
          random.order=FALSE, 
	       rot.per=0.35,
	       use.r.layout=FALSE,
	       colors=pal)
```

device analysis androdid vs iOS: when is tweeted
========================================================


```{r, echo=FALSE}
tweetsSmall <- tweets3 %>%
  select(id, statusSource, text, created) %>%
  extract(statusSource, "source", "Twitter for (.*?)<") %>%
  filter(source %in% c("iPhone", "Android"))
tweetsSmall$created <- ymd_hms(tweetsSmall$created)

tweetsSmall %>%
  count(source, hour = hour(with_tz(created, "EST"))) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(hour, percent, color = source)) +
  geom_line() +
  scale_y_continuous(labels = percent_format()) +
  labs(x = "Hour of day (EST)",
       y = "% of tweets",
       color = "")
```
device analysis androdid vs iOS: tweets containing picture
========================================================


```{r, echo=FALSE}
tweet_picture_counts <- tweetsSmall %>%
  filter(!str_detect(text, '^"')) %>%
  count(source,
        picture = ifelse(str_detect(text, "t.co"),
          "Picture/link", "No picture/link"))
ggplot(tweet_picture_counts, aes(source, n, fill = picture)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "", y = "Number of tweets", fill = "")

```
device analysis androdid vs iOS: tweets with quotation marks
========================================================


```{r, echo=FALSE}
tweetsSmall %>%
  count(source,
        quoted = ifelse(str_detect(text,
                 '^"'), "Quoted", "Not quoted")) %>%
  ggplot(aes(source, n, fill = quoted)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "", y = "Number of tweets", fill = "") +
  ggtitle('Whether tweets start with a quotation mark (")')

```
device analysis androdid vs iOS: frequent words
========================================================


```{r, echo=FALSE}
android_iphone_ratios <- tweet_words %>%
  count(word, source) %>%
  filter(sum(n) >= 5) %>%
  spread(source, n, fill = 0) %>%
  ungroup() %>%
  mutate_each(funs((. + 1) / sum(. + 1)), -word) %>%
  mutate(logratio = log2(Android / iPhone)) %>%
  arrange(desc(logratio))

android_iphone_ratios %>%
  group_by(logratio > 0) %>%
  top_n(15, abs(logratio)) %>%
  ungroup() %>%
  mutate(word = reorder(word, logratio)) %>%
  ggplot(aes(word, logratio, fill = logratio < 0)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Android / iPhone log ratio") +
  scale_fill_manual(name = "", labels = c("Android", "iPhone"),
                    values = c("red", "lightblue"))


```
number of tweets over time
========================================================

tweets <- read.csv("data/trumpTweets.csv")
tweets$created <- ymd_hms(tweets$created)
ggplot(data = tweets, aes(x = created)) +
        geom_histogram(aes(fill = ..count..)) +
        theme(legend.position = "none") +
        xlab("Time") + ylab("Number of tweets") + 
        scale_fill_gradient(low = "midnightblue",
                            high = "aquamarine4")
```

how the data was collected
========================================================

- socialMediaLab package


reproducible research
========================================================

- latex, knitR, rMarkdown
